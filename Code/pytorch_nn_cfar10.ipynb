{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Users\\DeLL\\Desktop\\ML\\pyTorch_youtube\\Data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\DeLL\\Desktop\\ML\\pyTorch_youtube\\Data\\cifar-10-python.tar.gz to C:\\Users\\DeLL\\Desktop\\ML\\pyTorch_youtube\\Data\n"
     ]
    }
   ],
   "source": [
    "rootdir = r'C:\\Users\\DeLL\\Desktop\\ML\\pyTorch_youtube\\Data'\n",
    "T = datasets.CIFAR10(rootdir,train=True,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "V = datasets.CIFAR10(rootdir,train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = T[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x1E4389A3250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.classes[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'FiveCrop',\n",
       " 'Grayscale',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSizedCrop',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'Scale',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'functional',\n",
       " 'functional_pil',\n",
       " 'functional_tensor',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = to_tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "T = datasets.CIFAR10(rootdir,train=True,download=True,\n",
    "                    transform = transforms.ToTensor())\n",
    "V = datasets.CIFAR10(rootdir,train=False,download=True,\n",
    "                    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1662c452b0a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'CIFAR10' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t,y = T[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tL = torch.utils.data.DataLoader(T,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vL = torch.utils.data.DataLoader(V,batch_size=64,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072,200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200,10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8271985054016113\n",
      "1.4406744241714478\n",
      "1.6483951807022095\n",
      "1.6231807470321655\n",
      "1.1682177782058716\n"
     ]
    }
   ],
   "source": [
    "ne = 5\n",
    "for e in range(ne):\n",
    "    for X,y in tL:\n",
    "        batch_size = X.shape[0]\n",
    "        y_hat = model(X.view(batch_size,-1))\n",
    "        loss = loss_fn(y_hat,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3901\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t = 0\n",
    "with torch.no_grad():\n",
    "    for Xv,yv in vL:\n",
    "        batch_size = Xv.shape[0]\n",
    "        y_hat = model(Xv.view(batch_size,-1))\n",
    "        _,p = torch.max(y_hat,dim=1)\n",
    "        t+=yv.shape[0]\n",
    "        c += int((p==yv).sum())\n",
    "        \n",
    "print(c/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
